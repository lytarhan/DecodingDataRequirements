{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulations: How much data do you need for a decoding analysis?\n",
    "##### Leyla Tarhan\n",
    "##### ltarhan@g.harvard.edu\n",
    "##### 4/2020\n",
    "\n",
    "### This is a question that comes up a lot in fMRI world. Say you want to use decoding to detect whether there's a difference between two categories (e.g., big and small objects). How much data (e.g., runs or blocks or subjects) should you collect for each category?\n",
    "\n",
    "### Here, I'm taking a simulation-based approach to ask two questions: \n",
    "\n",
    "### Q1: How much data do you need to detect a real difference between categories?\n",
    "#### To address this, I'm simulate data with the following assumptions:\n",
    "1. There is a real difference between the categories\n",
    "2. The effect size of the difference is XXX\n",
    "3. I'm drawing data from 100 dimensions (in the fMRI case, each dimension is a voxel) and the data for each category is normally distributed (with some offset) in 100-dimensional space\n",
    "\n",
    "Having simulated data that meet these assumptions, I'll iteratively draw a random sample from each category, and do 2-way classification to see if I can separate the categories. The size of the sample I draw will range from 10 to 100. The result will be a plot of the average classification accuracy (on held-out data) over samples of 10-100 data points. This can be interpreted as accuracy at detecting \"true\" positives (a real difference between categories).\n",
    "\n",
    "\n",
    "### Q2. How much data do you need to avoid detecting a difference that isn't real?\n",
    "#### Here, I'll take a similar approach with slightly different assumptions:\n",
    "1. There is NOT a real difference between the categories\n",
    "2. I'll draw data from a single 100-dimensionsal distribution.\n",
    "\n",
    "Again, I'll iteratively draw a random sample from each \"category,\" and do 2-way classification with sample sizes ranging from 10-100 points per category. This time, the result will be a plot of the average classifiction accuracy (which should be at chance, given that there's no real difference between these categories) for each sample size. This can be interpreted as the detection rate for false positives (an apparent difference when there is none)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## to-do:\n",
    "# [] get the base case working\n",
    "# [] add in iterations\n",
    "# [] add in loop through sample sizes (make these not nested?)\n",
    "# [] plot the results\n",
    "# [] add in scrambled baseline\n",
    "\n",
    "# [] q2 (same as q1 but category means are the same)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "## import libraries\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "## General Setup\n",
    "# variables for answering both questions\n",
    "\n",
    "nVox = 100 # number of voxels (or other dimensions)\n",
    "nIters = 100 # how many times you sample data of each size\n",
    "\n",
    "# training-testing split for classification analyses:\n",
    "trainProp = .8 # 80% of data in each category used for training\n",
    "testProp = .2 # 20% used for testing\n",
    "\n",
    "# possible sample sizes\n",
    "minN = 10\n",
    "maxN = 100\n",
    "nRange = range(minN, maxN+1)\n",
    "\n",
    "# set up variance-covariance matrix for the multi-variate normal distributions:\n",
    "covMat = np.identity(nVox)\n",
    "# # plot it to check:\n",
    "# plt.matshow(covMat);\n",
    "# plt.colorbar()\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "# seed a random number generator:\n",
    "np.random.seed(444)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1 - detecting a real difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2]\n"
     ]
    }
   ],
   "source": [
    "## setup for this section\n",
    "\n",
    "# multi-variate means for the 2 categories' activation distributions:\n",
    "popMeans_q1 = [1, 2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "## sample the data & classify the categories\n",
    "\n",
    "# set up the multivariate means for each category:\n",
    "cat1Means_q1 = np.full((nVox), popMeans_q1[0]) # length = # voxels (dimensions)\n",
    "cat2Means_q1 = np.full((nVox), popMeans_q1[1]) \n",
    "\n",
    "# start small: 1 iteration at 1 sample size\n",
    "n = nRange[0]\n",
    "currAccuracy = [] # set up an array to store classification accuracy for this sample size\n",
    "i = 1\n",
    "\n",
    "# figure out how much data is in the training / testing splits:\n",
    "nTrain = round(trainProp*n)\n",
    "nTest = n-nTrain\n",
    "\n",
    "# sample from category 1:\n",
    "cat1Train_q1 = np.random.multivariate_normal(cat1Means_q1, covMat, nTrain) # training data (training sample size x voxels)\n",
    "cat1Test_q1 = np.random.multivariate_normal(cat1Means_q1, covMat, nTest) # testing data (test sample size x voxels)\n",
    "\n",
    "# sample from category 2:\n",
    "cat2Train_q1 = np.random.multivariate_normal(cat2Means_q1, covMat, nTrain) # training data\n",
    "cat2Test_q1 = np.random.multivariate_normal(cat2Means_q1, covMat, nTest) # testing data\n",
    "\n",
    "# [] train a classifier to distinguish between the 2 categories (using training data)\n",
    "\n",
    "# [] test the classifier on the testing data\n",
    "\n",
    "# [] calculate accuracy (% of testing data that was correctly classified)\n",
    "# [] store it (in an array: currAccuracy)\n",
    "\n",
    "\n",
    "\n",
    "# [] after looping through the iterations for this sample size, add the array to a dictionary (?)\n",
    "\n",
    "# after looping through all the sample sizes, result = a dictionary (?) with classification accuracies across iterations for every sample size.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## plot average classification accuracy over sample sizes\n",
    "\n",
    "# [] do it."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
